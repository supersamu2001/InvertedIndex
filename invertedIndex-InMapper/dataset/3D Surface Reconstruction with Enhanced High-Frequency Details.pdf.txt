3D Surface Reconstruction with Enhanced High-Frequency Details Shikun Zhanga, Yiqun Wangb,∗, Cunjian Chena,∗, Yong Lib, Qiuhong Kea aDepartment of Data Science and AI, Monash University, Melbourne, 3800, Victoria, Australia bCollege of Computer Science, Chongqing University, Chongqing, 401331, China Abstract Neural implicit 3D reconstruction can reproduce shapes without 3D super- vision, and it learns the 3D scene through volume rendering methods and neural implicit representations. Current neural surface reconstruction meth- ods tend to randomly sample the entire image, making it difficult to learn high-frequency details on the surface, and thus the reconstruction results tend to be too smooth. We designed a method (FreNeuS) based on high-frequency information to solve the problem of insufficient surface detail. Specifically, FreNeuS uses pixel gradient changes to easily acquire high-frequency regions in an image and uses the obtained high-frequency information to guide sur- face detail reconstruction. High-frequency information is first used to guide the dynamic sampling of rays, applying different sampling strategies accord- ing to variations in high-frequency regions. To further enhance the focus on surface details, we have designed a high-frequency weighting method that constrains the representation of high-frequency details during the reconstruc- tion process. Qualitative and quantitative results show that our method can reconstruct fine surface details and obtain better surface reconstruction qual- ity compared to existing methods. In addition, our method is more applicable and can be generalized to any NeuS-based work. Keywords: 3D Reconstruction, Novel View Synthesis, Neural Radiance Field, Frequency Constraints ∗Corresponding authors. Preprint submitted to J. Vis. Commun. Image Represent. May 7, 2025 arXiv:2505.03362v1  [cs.CV]  6 May 2025 1. Introduction Reconstructing a 3D shape from a set of images is an important and challenging task in the field of computer vision [1]. Recently, the pioneer- ing work NeRF [2] has garnered significant attention since its inception. It combines neural radiance field and volume rendering to achieve high-quality novel view synthesis and implicit representation of 3D shapes. New 3D re- construction methods based on NeRF were subsequently proposed by NeuS [3] and VolSDF [4], which introduced signed distance function (SDF) to re- construct smooth surface models. However, all these works have room for improvement in reconstructing surface details. In general, the quality of surface detail reconstruction can be improved by increasing the number of sampled rays, but this undoubtedly increases the computational consumption. Currently, in order to obtain sufficient sam- pling information while controlling the computational cost, some methods address these challenges by expanding the sampling area around each ray. For example, as opposed to sampling point-by-point on a ray, Mip-NeRF [5] and Tri-MipRF [6] sample in the range of the conical table and Gaussian sphere, respectively. This type of methods expands the sampling range, but the sampling is random and does not guarantee that sufficient high-frequency information will be captured. Subsequently, in order to provide more infor- mation for the reconstruction of surface details, Guo [7] proposes the use of the Manhattan world hypothesis as an additional condition, while Yu [8] uses pseudo-depth supervision to constrain the reconstruction of texture regions. While this additional information provides additional constraints for surface reconstruction, it is not learned directly for high-frequency details. As an alternative to NeRF, 3DGS [9] has also achieved good success in 3D surface generation tasks. However, 3DGS often faces issues of over-reconstruction during Gaussian densification, where high-variance image regions are cov- ered by only a few large Gaussian blobs. This can hinder the learning of fine local details. Most of the subsequent work based on 3DGS has been devoted to solving the problem of over-reconstruction. Fre-GS [10] proposes to adjust the training process by constraining the amplitude and phase of high and low frequencies separately in the frequency space. This work also proposed the importance of high-frequency information in the image, but only constrained the relevant parameters in the frequency space and did not further use the high-frequency information to guide the reconstruction process. Our approach builds on these excellent works and seeks to further im- 2 Figure 1: Overview of our proposed Fre-NeuS. We first denoise the input RGB image using Gaussian filtering, then obtain the frequency distribution through the gradient detection module. Based on this distribution, we dynamically adjust the sampling rate to ensure sufficient capture of high-frequency details. We utilize the obtained high-frequency map to create a weight map in pixel space and adjust the optimization of pixels at different frequencies during model training accordingly. prove the quality of the reconstructed surface details. We observe that most of the texture detail information of the target image appears in the high- frequency regions of the surface mutations, which include parts such as depth value changes, color changes and illumination changes. These high-frequency regions can be captured by gradient detection, as shown in Fig. 2. The high- frequency image obtained by detection can clearly visualise the details of these surface changes. We further show the view reproduced by the baseline method NeuS [3], as shown in the third column of Fig. 2. We can clearly see that the view rendered by the baseline method is unable to reproduce these texture details (e.g., the texture of the roof). In this paper, we propose a simple but highly effective surface recon- struction method, FreNeuS, which solves the problem of overly smooth re- constructed surfaces by introducing high-frequency information. As shown in Fig. 1, FreNeuS introduces high-frequency information directly, using pixel gradient variations to detect the target image, thus obtaining an output containing only high-frequency detail variations. In general, low-frequency signals typically encode large-scale features (e.g., global shape and struc- ture, etc.), while high-frequency signals typically encode small-scale features (i.e., local details of a surface). Based on this principle, FreNeuS uses the high-frequency information as a guidance to dynamically adjust the ratio of ray sampling in high and low-frequency regions. Compared to random sampling, Fre-NeuS dynamically increases the number of samples in detailed regions, optimizing the overall sampling distribution. In addition, we propose a constraint mechanism for high-frequency information. By constraining the 3 Figure 2: The figure shows the obtained high-frequency image, along with the RGB images rendered by NeuS and Fre-NeuS, respectively. It can be seen that FreNeuS can improve the reconstruction accuracy of texture details by introducing high-frequency information, as demonstrated in features like the roof tile details in the image. high-frequency signals in pixel space, we seek to minimize the difference be- tween the details of the rendered image and the corresponding ground truth. The experimental results demonstrate that FreNeuS enhances the represen- tation of high-frequency texture details (e.g., roof textures, etc.), as shown in Fig. 2. Further, the overall quality of surface reconstruction is also improved, as shown in Table 1. The main contributions of this work are summarized here: • We propose a high-frequency enhancement module that reconstructs surface detail textures by introducing high-frequency information as additional input. • We propose an innovative dynamic sampling strategy based on high- frequency information, which ensures sufficient sampling of local de- tails. • A high-frequency information constraint mechanism is designed to en- hance the learning of high-frequency signals in pixel space, effectively minimizing surface detail errors. • Experiments on benchmark datasets demonstrate that Fre-NeuS excels in surface reconstruction and significantly enhances local detail accu- racy. Furthermore, the method integrates seamlessly into any NeuS- based framework, improving texture detail reconstruction. 2. Related Work Multi-view 3D reconstruction has been a challenging task in the field of computer vision. Traditional multi-view 3D reconstruction methods usually 4 use explicit geometry to express 3D structures, which can be classified into voxel-based methods [11, 12, 13, 14, 15, 16] and point-based methods [17, 18, 19, 20] according to the representation. The voxel-based approach has high memory overhead, while the point-based approach requires additional consideration of missing point clouds. Recently, neural implicit surface-based reconstruction methods have been proposed, which provide new ideas for novel view synthesis and surface reconstruction tasks. Subsequently, the 3D Gaussian Splatting technique for 3D scene modelling has also gained widespread support from researchers due to its efficient training speed and superior rendering quality. Here, we provide a brief review of these two methods. Neural surface reconstruction. Neural surface reconstruction is based on the neural implicit representation of surfaces, which uses successive neural implicit functions to reconstruct shapes from multi-view images. Neural Ra- diance Fields (NeRF) is a specific neural field application used mainly for 3D scene reconstruction and image synthesis. In the work of NeRF [2], it uses volume rendering to map a 3D density field and a 3D oriented colour field to a 2D image. Subsequent work, such as VolSDF [4] and NeuS [3], also in- corporates occupancy functions or signed distance functions into the volume rendering equation. Since the implicit function can be regularized by the Eikonal loss, the reconstructed surface can maintain smoothness. They also use MLP to model 3D scenes of multi-view 2D images and can generate new views with excellent multi-view consistency. Subsequently, many variants of NeuS have been designed in order to improve the accuracy of surface detail reconstruction. To further improve surface fidelity, HF-NeuS [21] introduces an additional MLP for modelling displacement fields to learn high-frequency details. In contrast to these methods, we believe that the reconstruction of local details can be more directly constrained by using high-frequency signals as guiding information, and therefore we propose the new method FreNeuS. Gaussian Splatting. Once proposed, the Gaussian Splatting technique has attracted much attention for its real-time rendering speed and excel- lent new view generation. The 3D Gaussian Splatting [9] introduces an anisotropic 3D Gaussian distribution and an efficient microscopic splash map, and then it utilises SfM [22] to estimate a dominant sparse point cloud from a set of multiple images. Therefore, compared with other 3D scene mod- elling methods, Gaussian Splatting has a great advantage in terms of train- ing speed. However, during Gaussian densification, too many 3D Gaussians tend to cause blurring of the reconstructed surface, making it difficult to 5 Figure 3: Visualisation comparisons on different scenes of the DTU dataset. First column: reference images. Second to fifth columns: NeuS, HF-NeuS, 3DGS, 2DGS, and OURS. Chamfer distance errors are labelled in the lower left corner, with smaller metrics being better. Our method achieves minimal error while effectively capturing surface details. For instance, in the fourth row of the bear scene, Fre-NeuS successfully reproduces both the tooth gap and the distinct leg folds. reproduce rich surface details. Based on this, several works [23, 24] extended 3DGS by modelling the normals as an additional attribute of the 3D Gaussian primitive. This year the proposal of 2D Gaussian [25] attracted scholars’ at- tention again. The method defines normals by using 2D Gaussian primitives to represent the tangent space of 3D surfaces, aligning them more closely with the underlying geometry. This method reconstructs a smoother surface compared to 3DGS. Both the method based on neural implicit surfaces and the method based on Gaussian Splatting techniques are outstanding repre- sentatives of current surface reconstruction tasks. Therefore, we compare FreNeuS with the excellent work mentioned above. 6 3. Method Given a set of images and their corresponding camera positions, the goal of FreNeuS is to reconstruct a 3D scene represented by signed distance func- tions (SDF). FreNeuS aims to enhance surface detail reconstruction by lever- aging high-frequency information as guidance. In this section, we first de- scribe how to detect the target image by analyzing pixel gradient changes, which allows us to obtain high-frequency information. Next, we demon- strate how the sampling ratio can be dynamically adapted based on the extracted high-frequency information. Finally, we present the design of the high-frequency information constraint mechanism. 3.1. High-frequency Detection Compared to the original image, high-frequency maps offer a clearer representation of surface detail changes. We propose a high-frequency en- hancement module to capture frequency information. It detects high and low frequencies by identifying changes in gradient intensity. Points in high- frequency regions are considered high-frequency points, including areas of depth discontinuities, scene lighting variations, and other critical transitions. These points reflect surface inconsistencies and highlight regions that require attention during the reconstruction process. In the process of extracting high-frequency maps, the first Gaussian filter G(x, y) is used to remove the noise from the input image. Next, we com- pute the gradient and orientation. Gx(x, y) and Gy(x, y) denote the gradient values in horizontal and vertical directions respectively. Accordingly, the gradient intensity and direction can be calculated as: M(x, y) = q G2 x(x, y) + G2 y(x, y) , θ(x, y) = tan−1 Gy(x, y) Gx(x, y)  . (1) Here, M(x, y) denotes the gradient intensity of the pixel point and θ(x, y) denotes the gradient direction of the pixel point. Then, boundary tracing is performed based on the grayscale threshold to identify the high-frequency regions of the image. After obtaining the high-frequency distribution of the image, it is fed into the network to guide the subsequent surface reconstruc- tion task. 7 3.2. High-frequency Dynamic Sampling Most NeuS-based approaches utilize random sampling as their strategy, where a batch of rays is randomly selected from the set of candidate pixels in the target image. Random sampling is simple to operate and ensures the diversity of batches in each sampling. However, in the reconstructed scene image, smooth regions without texture details account for a large proportion, and if a random sampling strategy is used to collect rays from the target image, it naturally leads to under-sampling of regions with high-frequency detail variations. This is not conducive to recovering fine details on the object surface. We observe that most of these details are concentrated in high-frequency regions. To address this, we propose a novel high-frequency- guided ray sampling strategy that dynamically adjusts sampling ratios across different regions based on high-frequency information. First, we determine the high-frequency pixel set based on the frequency distribution of the target image, as shown in Eqn. (2): IH, IL =  Pe > 0, P ∈IH Pe <= 0, P ∈IL. (2) In Fig. 1, the red arrows on the high-frequency map represent high- frequency pixels, while the blue arrows indicate low-frequency pixels. Here, Pe denotes the pixel value of the point pixel point P in the high-frequency map, and the high-frequency pixel set IH of the target image is obtained after the above processing. Correspondingly, the set of low-frequency region pixels in the target image is IL. Then, instead of setting fixed sampling weights, we randomly sample each target image according to the proportion of high-frequency and low-frequency regions in it. This approach allows for dynamic adjustment of sampling for each target image, ensuring that sampling is both balanced and targeted. Mathematically, this could be described as: Hnum = w ∗B, Lnum = (1 −w) ∗B. (3) Specifically, the ratio of high-frequency pixels to low-frequency pixels is used as the sampling weight w, i.e., w = IH/IL, and B represents the total number of rays sampled at each step during the training process. The Hnum in Eqn. (3) denotes the number of samples in the high-frequency pixel set, and Lnum denotes the number of samples in the low-frequency pixel set. 8 Then according to the number of samples, random samples are taken in IH and IL, respectively. The advantage of this approach is that it preserves the randomness of sampling while ensuring a higher sampling rate in detail areas through constraints based on high-frequency information. This is beneficial for reproducing detailed textures in the reconstruction. 3.3. High-frequency Constraint Mechanisms As mentioned earlier, it is crucial to distinguish the contribution of high- frequency regions from that of low-frequency regions. Previously, we em- ployed dynamic sampling to ensure adequate representation of high-frequency regions, thereby improving the learning of high-frequency detail textures. Furthermore, by looking at the rendered view of the baseline NeuS, we found that the detail regions in the view were largely blurred and still lacked finer texture. As shown in Fig. 2, the baseline NeuS rendered view is noticeably lacking in details such as roofs, windows, etc. compared to the original im- age. This can be summarized as: the rendered view appears overly smooth in areas with sharp texture details. Based on this, we believe that in addition to enhancing the sampling of high-frequency regions, we can add limiting constraints to these regions based on high-frequency map. Specifically, we add additional constraints to the high-frequency signals in pixel space during the rendering process, as shown in Eqn. (4): WHigh =  w1 High , w2 High , . . . .., wn High  , wi High =  a, P ∈IH b, P /∈IH. (4) First, we assess whether the sampled ray falls within a high-frequency region based on pixel values, and then assign weights to the ray according to this assessment. The weight of the ray in the high-frequency region is a, and the weight of the ray in the low-frequency region is b. The WHigh denotes the set of weights of all sampled rays, and wi High denotes the weight of the ith pixel. After obtaining the set of pixel weights, these weights will be used to constrain the expression of high-frequency pixels during the training process, as illustrated in Eqn. (5): LFrecolor = 1 |S| X s∈S  bCs −Cs  WHigh , (5) 9 where bCs is the ground truth color, the volume rendering color is Cs, and S is the total number of sampled pixel sets. After constraining the high- frequency pixels, the model further improves the reconstruction quality of the surface texture details. Specific results are shown in Table 3 and Fig. 5. 3.4. Optimization In addition to using high-frequency constraints to limit the rendered color, we also use Eikonal loss [26]. Eikonal loss is a regularised loss on the set of sampled points I that constrains the implicit function, as shown in Eqn. (6): Lreg = 1 |I| X i∈I [(∥∇S (xi, yi, zi∥)] −1 . (6) We train our network using both the rendering loss Legcolor and Eikonal loss Lreg functions as shown below: Ltotal = Lreg + λLFrecolor. (7) 4. Experiments Dataset. We first conducted experiments on the DTU dataset [27], which shows all real scenes. DTU is a multi-view stereo dataset, where each scene consists of 49 or 64 views with a resolution of 1600 × 1200. We fol- lowed the previous method to select the same 15 scene data from it. We further selected six challenging scenes from other datasets, the NeRF syn- thetic dataset [2]. The NeRF synthetic dataset [2] has an image resolution of 800×800 and provides 100 views per scene. We chose this dataset to analyse the reconstruction of high-frequency details. Baseline. We compare FreNeuS with the following five state-of-the-art baselines: (1) NeuS [3] is the most relevant baseline for our work, and much of the current work is based on NeuS. (2) VolSDF [28] is the work related to NeuS, which is also a very popular framework, and it performs well. (3) HF-NeuS [21] is one work based on NeuS, which proposes to construct SDF functions using displacement functions and achieves good results. (4) In addition to the NeuS-based work, we also selected the current state-of-the-art Gaussian Splatting-based work, 3DGS [29] and 2DGS [29]. For all methods, we used a threshold of 25 to extract surfaces for comparison. Evaluation metrics. To evaluate the quality of the reconstruction, we followed previous work and used the evaluation metrics Chamfer distance 10 (lower values are better). Following the official protocol, the background in the DTU dataset is not part of the ground truth surface, so we followed the previous method to remove the background when calculating the chamfer distance. NeRF synthetic dataset [2] does not have a background, so we calculated the chamfer distance between the ground truth shape and the reconstructed surface. Method 24 37 40 55 63 65 69 83 97 105 106 110 114 118 122 Mean NeRF 1.90 1.60 1.85 0.58 2.28 1.27 1.47 1.67 2.05 1.07 0.88 2.53 1.06 1.15 0.96 1.49 VOLSDF 1.14 1.26 0.81 0.49 1.25 0.70 0.72 1.29 1.18 0.70 0.66 1.08 0.42 0.61 0.55 0.86 NeuS 1.00 1.37 0.93 0.43 1.10 0.65 0.57 1.48 1.09 0.83 0.52 1.20 0.35 0.49 0.54 0.84 HF-NeuS 0.76 1.32 0.70 0.39 1.06 0.63 0.63 1.15 1.12 0.80 0.52 1.22 0.33 0.49 0.50 0.77 3DGS 2.14 1.53 2.08 1.68 3.49 2.21 1.43 2.07 2.22 1.75 1.79 2.55 1.53 1.52 1.50 1.96 2DGS 0.48 0.91 0.39 0.39 1.01 0.83 0.81 1.36 1.27 0.76 0.70 1.40 0.40 0.76 0.52 0.80 FreNeuS (ours) 0.81 0.82 0.74 0.37 0.97 0.56 0.58 1.40 1.19 0.72 0.53 1.13 0.32 0.46 0.42 0.73 Table 1: Quantitative results on DTU (the header’s numbers denote scene IDs). It can be seen that our method minimises the average error across all scenarios. Implementation details. Our overall network framework follows the structure of NeuS and uses an 8-layer MLP structure. We trained the network using Adam with a learning rate of 5e −4 and we used an NVIDIA RTX A6000 48GB GPU. For training, a total of 512 rays are sampled in each batch, the sampling region is assigned according to section 3, and then 64 points are uniformly sampled on the rays. Then we calculate the SDF value and its gradient, and fine sampling is performed again based on the SDF value. The sampling of the view is completed by following the strategy from coarse to fine. In addition, we set λ to 1.2. 4.1. Comparison In Table 1, we compare the chamfer distance error of FreNeuS with 3DGS, 2DGS, and several other NeuS-based methods on the dataset DTU. We can observe that FreNeuS achieves the smallest error in most of the scenes, and it also achieves the best average performance in all scenes. Furthermore, we show the visualisation of some of the scenes in Fig. 3. Compared to other methods, the FreNeuS reconstruction of the surface is more noise-resistant and more accurate in reconstructing the local details of the surface. For example, for the bronze statue in the third row, the FreNeuS reconstructed surface has clearer facial lines and less noise on the stomach. In the fourth row of the bears, Fre-NeuS accurately reproduces the details of the teeth gaps, and the leg folds are more clearly defined. In contrast, NeuS and HF-NeuS fail to capture these finer details as effectively. 11 Method Chair Ficus Lego Materials Mic Ship Mean VOLSD 1.26 1.54 2.83 1.35 3.62 2.92 2.37 NeuS 0.74 1.21 2.35 1.30 3.89 2.33 1.97 HF-NeuS 0.69 1.12 0.94 1.08 0.72 2.18 1.12 FreNeuS (ours) 0.45 0.63 1.30 0.13 2.7 1.50 1.11 Table 2: Quantitative results on the NeRF-synthetic dataset. Figure 4: Qualitative evaluation on the Ship and Material scenes. First column: reference images. Second to the fourth column: NeuS, HF-NeuS, and OURS. Compared to other methods, the inner circle of the sphere reconstructed by FreNeuS is more visible and the sail texture is much clearer. Most of the scenes in the DTU dataset are smooth surfaces where high- frequency details are not apparent. Therefore, we selected six challenging datasets from the NeRF synthetic dataset [2] for comparison. As shown in Table 2, we show the results of FreNeuS and other methods in the six synthetic data. Based on the evaluation results, it can be seen that FreNeuS achieves the smallest error in the average results of all the scenes. Among them, the performance in the Mic scene has a greater improvement compared to the baseline NeuS, but not as good as HF-NeuS. we analysed that it is because of the lack of high-frequency lines in the stent portion of the Mic itself, which has less impact on the global after adding the high-frequency constraints. In addition, in order to visualise the reconstruction effect on local details, we show a visual comparison of FreNeuS with the other two methods in Fig. 4. In the first row of the ship scene, Fre-NeuS reconstructs the cut- out details of the sails and the long mast section. In comparison, NeuS and HF-NeuS fail to capture the long mast and the sail cut-outs, respectively. In the second row of material scenes, the segmentation of the ball and base by HF-NeuS is not clear, and NeuS does not clearly reconstruct the small inner-most circle of the ball. 12 Figure 5: Visualisation of ablation experiments to verify the performance of each module. First column: the reference image. Second to fifth columns: NeuS, use of high-frequency constraints, use of high-frequency dynamic sampling strategies, and FreNeuS. It can be observed that as the two modules are added, the reconstructed surface details become clearer and more refined. 4.2. Ablation Study 4.2.1. Design verification We conducted quantitative experiments on the DTU dataset to assess the impact of various modules on reconstruction results, including the high- frequency dynamic sampling and high-frequency constraint mechanisms. In Table 3, ‘Base’ denotes the baseline method, i.e., NeuS; ‘+sampling’ denotes the high-frequency guided ray sampling strategy; ‘+Fre-constraints ‘ denotes the high-frequency constraints mechanism. We use ‘FreNeuS’ as the com- plete structure of our proposed method. Based on the data in Table 3, it can be seen that both of our proposed modules improve the fidelity of the reconstruction. In addition, we show the view comparison in Fig. 5. This also demonstrates that FreNeuS is effective in reconstructing surface details using high-frequency information. Method 24 37 40 55 63 65 69 83 97 105 106 110 114 118 122 Mean Base 1.00 1.37 0.93 0.43 1.10 0.65 0.57 1.48 1.09 0.83 0.52 1.20 0.35 0.49 0.54 0.84 +Fre-constraints 0.85 0.86 0.73 0.37 1.04 0.60 0.58 1.42 1.21 0.77 0.57 1.11 0.33 0.43 0.44 0.75 +sampling 0.72 0.97 0.81 0.36 1.01 0.55 0.58 1.42 1.17 0.79 0.56 1.13 0.33 0.42 0.44 0.75 FreNeuS 0.81 0.82 0.74 0.37 0.97 0.56 0.58 1.40 1.19 0.72 0.53 1.13 0.32 0.46 0.42 0.73 Table 3: Ablation study results (chamfer distance) on the DTU (the number in the header indicates the scene ID). To further validate the effectiveness of our proposed high-frequency guid- ance method, we compare Fre-NeuS with the global enhancement sampling 13 method, LoD-NeuS[30]. LoD-NeuS projects four additional rays through the pixel corners, forming a cone-shaped region and sampling its vertices. This approach extends the sampling area for each pixel and uniformly increases the sampling density at each pixel point. We made comparisons on the DTU dataset, as shown in Table 4, compared to LoD-NeuS, our proposed Fre- NeuS achieves similar results in terms of average error while using less GPU memory with the same training time. This indicates that Fre-NeuS achieves the same effectiveness as global enhanced sampling but with significantly reduced computational cost. Method Train Time GPU Memory Chamfer distance LoD-NeuS 9h 13G 0.72 FreNeuS (ours) 9h 8.7G 0.73 Table 4: Comparison of GPU Memory, Chamfer distance and Time Consumption with LoD-NeuS, a Global Enhanced Sampling Approach. 4.2.2. Generalization validation Both modules proposed in FreNeuS: the High-frequency dynamic sam- pling and the High-frequency constraint mechanisms can be migrated to other NeuS-based models, and they can improve the accuracy of the model in reconstructing local details. To verify this, we conduct experiments us- ing HF-NeuS as an example. Firstly, we add the high-frequency constraints mechanism to HF-NeuS, and ‘+constraints’ in the second row of Table 5 rep- resents this scheme. Then we complete adding two modules to HF-NeuS, the ‘+sampling+cons’ in the third row represents this scheme. From the data in Table 5, we can see that both schemes proposed by FreNeuS can improve the accuracy of HF-NeuS. We show the visualisation results in Fig. 6, where we can see that with the addition of the two FreNeuS modules, the local details of the HF-NeuS reconstruction are clearer. 4.2.3. Runtime and storage analysis To compare the time required for model training, we report the runtime of FreNeuS on the DTU dataset. Neither of the two modules proposed in FreNeuS—the high-frequency constraint mechanism and the high-frequency dynamic sampling strategy—adds extra computational time. Therefore the training time of FreNeuS is close to that of NeuS, both approaching 9 hours on NVIDIA RTX A6000 48GB GPUs. 14 Method 24 37 55 63 65 69 97 105 110 114 118 122 Mean HF-NeuS 0.76 1.32 0.39 1.06 0.63 0.63 1.12 0.80 1.22 0.33 0.49 0.50 0.77 +constraints 0.61 1.04 0.37 1.00 0.59 0.63 1.21 0.79 1.20 0.33 0.48 0.48 0.73 +sampling+cons 0.62 0.98 0.36 0.97 0.61 0.64 1.19 0.75 1.20 0.33 0.49 0.48 0.71 Table 5: In order to validate the generalizability of the FreNeuS proposed method, a high-frequency constraint mechanism and a high-frequency dynamic sampling strategy are added to the HF-NeuS model. The performance comparison shows that the method proposed by FreNeuS can be adapted to other methods. Figure 6: Visual comparisons of improved HF-NeuS after integrating the two proposed modules of FreNeuS. It can be seen that with the addition of the high-frequency constraint mechanism and the high-frequency dynamic sampling strategy, the details of the surface reconstructed by HF-NeuS are clearer. For example, the texture of the pumpkin is more obvious, and the stem of the apple on the far right is also reconstructed. In addition, compared to NeuS, FreNeuS adds the high-frequency detec- tion process, which takes about 3 minutes on average on each scene. There- fore, compared to the baseline FreNeuS does not consume too much extra time. Similarly, migrating the FreNeuS method to HF-NeuS does not add too much extra consumption. In terms of scene memory, the average size of all scenes in DTU is used for comparison. As shown in Table 6, the method introduced by FreNeuS also does not add extra memory. Method HF-NeuS HF+Sampling+constrain NeuS FreNeuS Time 22h 22h 9h 9 Memory 42.15MB 42.5MB 30.13MB 30MB Table 6: Memory and time analysis. The approach presented in FreNeuS is not only generalizable but also does not add excessive consumption. The performance of the original model is not degraded, either in terms of training time or memory. 15 5. Conclusion We present a simple and effective high-frequency guided surface detail reconstruction method, FreNeuS. We observe that local details of the surface can be more clearly represented in the high-frequency image, and there- fore utilise the change in pixel gradient to obtain a high-frequency output. FreNeuS then uses the high-frequency information to guide the dynamic sam- pling of the rays, ensuring that more local detail information is obtained. In addition, to further constrain the reconstruction of texture details, FreNeuS introduces a high-frequency constraint mechanism that constrains the ex- pression of high-frequency information in pixel space. Experiments show that FreNeuS achieves better results in the surface reconstruction task, and it can effectively reproduce surface details. It is worth noting that despite its simplicity, our method has commendable migration properties that make it applicable to any NeuS-based task. References [1] R. Hartley, A. Zisserman, Multiple view geometry in computer vision, Cambridge university press, 2003. 2 [2] B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ramamoor- thi, R. Ng, Nerf: Representing scenes as neural radiance fields for view synthesis, Communications of the ACM 65 (1) (2021) 99–106. 2, 5, 10, 11, 12 [3] P. Wang, L. Liu, Y. Liu, C. Theobalt, T. Komura, W. Wang, Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction, arXiv preprint arXiv:2106.10689 (2021). 2, 3, 5, 10 [4] L. Yariv, J. Gu, Y. Kasten, Y. Lipman, Volume rendering of neural implicit surfaces, Advances in Neural Information Processing Systems 34 (2021) 4805–4815. 2, 5 [5] J. T. Barron, B. Mildenhall, M. Tancik, P. Hedman, R. Martin-Brualla, P. P. Srinivasan, Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields, in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 5855–5864. 2 16 [6] W. Hu, Y. Wang, L. Ma, B. Yang, L. Gao, X. Liu, Y. Ma, Tri-miprf: Tri- mip representation for efficient anti-aliasing neural radiance fields, in: Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023, pp. 19774–19783. 2 [7] H. Guo, S. Peng, H. Lin, Q. Wang, G. Zhang, H. Bao, X. Zhou, Neural 3d scene reconstruction with the manhattan-world assumption, in: Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 5511–5520. 2 [8] Z. Yu, S. Peng, M. Niemeyer, T. Sattler, A. Geiger, Monosdf: Exploring monocular geometric cues for neural implicit surface reconstruction, Ad- vances in neural information processing systems 35 (2022) 25018–25032. 2 [9] B. Kerbl, G. Kopanas, T. Leimk¨uhler, G. Drettakis, 3d gaussian splat- ting for real-time radiance field rendering, ACM Transactions on Graph- ics 42 (4) (2023) 1–14. 2, 5 [10] J. Zhang, F. Zhan, M. Xu, S. Lu, E. Xing, Fregs: 3d gaussian splat- ting with progressive frequency regularization, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 21424–21433. 2 [11] A. Broadhurst, T. W. Drummond, R. Cipolla, A probabilistic framework for space carving, in: Proceedings eighth IEEE international conference on computer vision. ICCV 2001, Vol. 1, IEEE, 2001, pp. 388–393. 5 [12] J. S. De Bonet, P. Viola, Poxels: Probabilistic voxelized volume re- construction, in: Proceedings of International Conference on Computer Vision (ICCV), Vol. 2, Citeseer, 1999, p. 2. 5 [13] S. Izadi, D. Kim, O. Hilliges, D. Molyneaux, R. Newcombe, P. Kohli, J. Shotton, S. Hodges, D. Freeman, A. Davison, et al., Kinectfusion: real-time 3d reconstruction and interaction using a moving depth cam- era, in: Proceedings of the 24th annual ACM symposium on User inter- face software and technology, 2011, pp. 559–568. 5 [14] K. N. Kutulakos, S. M. Seitz, A theory of shape by space carving, In- ternational journal of computer vision 38 (2000) 199–218. 5 17 [15] M. Nießner, M. Zollh¨ofer, S. Izadi, M. Stamminger, Real-time 3d recon- struction at scale using voxel hashing, ACM Transactions on Graphics (ToG) 32 (6) (2013) 1–11. 5 [16] S. M. Seitz, C. R. Dyer, Photorealistic scene reconstruction by voxel coloring, International journal of computer vision 35 (1999) 151–173. 5 [17] C. Barnes, E. Shechtman, A. Finkelstein, D. B. Goldman, Patchmatch: A randomized correspondence algorithm for structural image editing, ACM Trans. Graph. 28 (3) (2009) 24. 5 [18] S. Galliani, K. Lasinger, K. Schindler, Gipuma: Massively parallel multi- view stereo reconstruction, Publikationen der Deutschen Gesellschaft f¨ur Photogrammetrie, Fernerkundung und Geoinformation e. V 25 (361- 369) (2016) 2. 5 [19] J. L. Schonberger, J.-M. Frahm, Structure-from-motion revisited, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 4104–4113. 5 [20] J. L. Sch¨onberger, E. Zheng, J.-M. Frahm, M. Pollefeys, Pixelwise view selection for unstructured multi-view stereo, in: Computer Vision– ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part III 14, Springer, 2016, pp. 501– 518. 5 [21] Y. Wang, I. Skorokhodov, P. Wonka, Hf-neus: Improved surface recon- struction using high-frequency details, Advances in Neural Information Processing Systems 35 (2022) 1966–1978. 5, 10 [22] N. Snavely, S. M. Seitz, R. Szeliski, Photo tourism: exploring photo collections in 3d, in: ACM siggraph 2006 papers, 2006, pp. 835–846. 5 [23] Y. Jiang, J. Tu, Y. Liu, X. Gao, X. Long, W. Wang, Y. Ma, Gaus- sianshader: 3d gaussian splatting with shading functions for reflective surfaces, arXiv preprint arXiv:2311.17977 (2023). 6 [24] J. Gao, C. Gu, Y. Lin, H. Zhu, X. Cao, L. Zhang, Y. Yao, Relightable 3d gaussian: Real-time point cloud relighting with brdf decomposition and ray tracing, arXiv preprint arXiv:2311.16043 (2023). 6 18 [25] B. Huang, Z. Yu, A. Chen, A. Geiger, S. Gao, 2d gaussian splatting for geometrically accurate radiance fields, arXiv preprint arXiv:2403.17888 (2024). 6 [26] A. Gropp, L. Yariv, N. Haim, M. Atzmon, Y. Lipman, Implicit geomet- ric regularization for learning shapes, arXiv preprint arXiv:2002.10099 (2020). 10 [27] R. Jensen, A. Dahl, G. Vogiatzis, E. Tola, H. Aanæs, Large scale multi- view stereopsis evaluation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2014, pp. 406–413. 10 [28] L. Yariv, Y. Kasten, D. Moran, M. Galun, M. Atzmon, B. Ronen, Y. Lip- man, Multiview neural surface reconstruction by disentangling geometry and appearance, Advances in Neural Information Processing Systems 33 (2020) 2492–2502. 10 [29] B. Huang, Z. Yu, A. Chen, A. Geiger, S. Gao, 2d gaussian splatting for geometrically accurate radiance fields, in: SIGGRAPH 2024 Conference Papers, Association for Computing Machinery, 2024. doi:10.1145/ 3641519.3657428. 10 [30] Y. Zhuang, Q. Zhang, Y. Feng, H. Zhu, Y. Yao, X. Li, Y.-P. Cao, Y. Shan, X. Cao, Anti-aliased neural implicit surfaces with encoding level of detail, in: SIGGRAPH Asia 2023 Conference Papers, 2023, pp. 1–10. 14 19 